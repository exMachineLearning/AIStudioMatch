{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 飞桨常规赛：遥感影像地块分割 - 4月第10名方案"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1. 准备下载相关库与数据解压"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'PaddleSeg'...\n",
      "remote: Enumerating objects: 10924, done.\u001b[K\n",
      "remote: Counting objects: 100% (10924/10924), done.\u001b[K\n",
      "remote: Compressing objects: 100% (5412/5412), done.\u001b[K\n",
      "remote: Total 10924 (delta 7389), reused 8171 (delta 5353), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (10924/10924), 156.94 MiB | 20.03 MiB/s, done.\n",
      "Resolving deltas: 100% (7389/7389), done.\n",
      "Checking connectivity... done.\n"
     ]
    }
   ],
   "source": [
    "#下载PaddleSeg\r\n",
    "!git clone https://gitee.com/paddlepaddle/PaddleSeg.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!unzip -q data/data77571/train_and_label.zip > /dev/null\r\n",
    "!unzip -q data/data77571/img_test.zip > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!rm -r __MACOSX/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2. 数据标签分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 255}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#测试输出图片\r\n",
    "pic1 = '/home/aistudio/lab_train/T020005.png'\r\n",
    "from PIL import Image\r\n",
    "import numpy as np\r\n",
    "img = Image.open(pic1)\r\n",
    "test  = np.array(img)\r\n",
    "# print(test.shape)\r\n",
    "a = test.flatten()\r\n",
    "set(a.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2.1 数据类型分布的分析\n",
    "<font size=\"5pt\" color=\"red\">注意：下面这部分数据分析的代码参考[坑姐](https://aistudio.baidu.com/aistudio/personalcenter/thirdview/90149)的[项目](https://aistudio.baidu.com/aistudio/projectdetail/1752986)，这部分数据分析的代码可以用于任何类似的任务，非常有学习的价值！</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2, os\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "#amount of classer\r\n",
    "CLASSES_NUM = 4\r\n",
    "\r\n",
    "#find imagee in folder dir\r\n",
    "def findImages(dir,topdown=True):\r\n",
    "    im_list = []\r\n",
    "    if not os.path.exists(dir):\r\n",
    "        print(\"Path for {} not exist!\".format(dir))\r\n",
    "        raise\r\n",
    "    else:\r\n",
    "        for root, dirs, files in os.walk(dir, topdown):\r\n",
    "            for fl in files:\r\n",
    "                im_list.append(fl)\r\n",
    "    return im_list\r\n",
    "\r\n",
    "# amount of images corresponding to each classes\r\n",
    "images_count = [0]*CLASSES_NUM\r\n",
    "# amount of pixels corresponding to each class\r\n",
    "class_pixels_count = [0]*CLASSES_NUM\r\n",
    "# amount of pixels corresponding to the images of each class\r\n",
    "image_pixels_count = [0]*CLASSES_NUM\r\n",
    "\r\n",
    "image_folder = './lab_train/'\r\n",
    "im_list = findImages(image_folder) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23707, 30151, 23044, 18978]\n",
      "[247142772, 310655521, 152480301, 159504650]\n",
      "[1553661952, 1975975936, 1510211584, 1243742208]\n"
     ]
    }
   ],
   "source": [
    "#######################################################注意！！！！！！！！！！！\r\n",
    "# 这部分代码没事就不要再次运行了，非常消耗时间！！\r\n",
    "for im in im_list:\r\n",
    "    # print(im)\r\n",
    "    cv_img = cv2.imread(os.path.join(image_folder, im), cv2.IMREAD_UNCHANGED)\r\n",
    "    size_img = cv_img.shape\r\n",
    "    colors = set([])\r\n",
    "    for i in range(size_img[0]):\r\n",
    "        for j in range(size_img[1]):\r\n",
    "            p_value = cv_img.item(i,j)\r\n",
    "            if not p_value < CLASSES_NUM: # check\r\n",
    "                pass\r\n",
    "                # print(p_value) #因为有255，所以不打印了\r\n",
    "            else:\r\n",
    "                class_pixels_count[p_value] = class_pixels_count[p_value] + 1\r\n",
    "                colors.add(p_value)\r\n",
    "    im_size = size_img[0]*size_img[1]\r\n",
    "    for n in range(CLASSES_NUM):\r\n",
    "        if n in colors:\r\n",
    "            images_count[n] = images_count[n] + 1\r\n",
    "            image_pixels_count[n] = image_pixels_count[n] + im_size\r\n",
    "\r\n",
    "print(images_count)\r\n",
    "print(class_pixels_count)\r\n",
    "print(image_pixels_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2841, 0.3572, 0.1753, 0.1834]\n"
     ]
    }
   ],
   "source": [
    "# t = class_pixels_count.copy()\r\n",
    "t = [247142772, 310655521, 152480301, 159504650]\r\n",
    "a = np.array(t).sum()\r\n",
    "for i in range(len(t)):\r\n",
    "    t[i] = round(t[i]/a, 4)\r\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<font color=\"red\" size=\"5pt\">小结：根据打印结果可知，可以看出类别比较均衡</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2.2 数据准备（生成用于训练得到标签文件）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio\n"
     ]
    }
   ],
   "source": [
    "%cd ~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The suffix of images is: .jpg \n",
      " The suffix of masks is .png!\n",
      "The samples of image and label is [('img_train/T057389.jpg', 'lab_train/T057389.png'), ('img_train/T040500.jpg', 'lab_train/T040500.png'), ('img_train/T039138.jpg', 'lab_train/T039138.png')]\n",
      "The effective number of image data is: 66652\n",
      "The split number of train data is: 63319\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from imghdr import what\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def get_all_date(dir_images, dir_masks):\n",
    "    \"\"\"生成训练、测试所需的txt文件\"\"\"\n",
    "    res = []\n",
    "    img_list = os.listdir(dir_images)\n",
    "    mask_list = os.listdir(dir_masks)\n",
    "    assert len(img_list) == len(mask_list)  #样本和标签数量肯定要一样\n",
    "    img_suffix = os.path.splitext(os.path.join(dir_images,img_list[0]))[1]\n",
    "    mask_suffix = os.path.splitext(os.path.join(dir_masks,mask_list[0]))[1]\n",
    "    print(f'The suffix of images is: {img_suffix} \\n The suffix of masks is {mask_suffix}!')\n",
    "    for i in range(len(img_list)):\n",
    "        img_name = img_list[i]\n",
    "        mask_name = os.path.splitext(img_name)[0]+mask_suffix\n",
    "        image_path = os.path.join(dir_images,img_name)\n",
    "        mask_path = os.path.join(dir_masks,mask_name)\n",
    "        if os.path.splitext(img_name)[0] == os.path.splitext(mask_name)[0] and what(image_path) and what(mask_path): \n",
    "            #样本和标签文件名一样（不包含后缀，因为后缀可能不一样），同时都为图片\n",
    "            res.append((image_path, mask_path))\n",
    "        else:\n",
    "            print(image_path, mask_path)\n",
    "    return res\n",
    "\n",
    "res = get_all_date('img_train', 'lab_train')\n",
    "print(f'The samples of image and label is {res[:3]}')\n",
    "print(f'The effective number of image data is: {len(res)}')\n",
    "random.shuffle(res)\n",
    "random.shuffle(res)\n",
    "pro = 0.95 #训练/验证比例\n",
    "pro_int = int(len(res)*pro)\n",
    "print(f'The split number of train data is: {pro_int}')\n",
    "with open('./train_list.txt', 'w') as f:\n",
    "    for line in res[:pro_int]:\n",
    "        f.writelines(line[0] + ' ' + line[1] + '\\n')\n",
    "\n",
    "with open('./val_list.txt', 'w') as f:\n",
    "    for line in res[pro_int:]:\n",
    "        f.writelines(line[0] + ' ' + line[1] + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3. 配置训练文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/PaddleSeg\n"
     ]
    }
   ],
   "source": [
    "#进入PaddleSeg目录\r\n",
    "%cd ./PaddleSeg/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<font size=\"4\">根据[自定义数据集文档](https://gitee.com/paddlepaddle/PaddleSeg/blob/release/v2.0/docs/data_prepare.md)自己继承并实现配置文件`PaddleSeg/configs/u2net/My_u2net_cityscapes_1024x512.yml`，运行下面的命令可以查看该文件的内容</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "  coef: [1, 1, 1, 1, 1, 1, 1]"
     ]
    }
   ],
   "source": [
    "!cat /home/aistudio/PaddleSeg/configs/u2net/My_u2net_cityscapes_1024x512.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.1 第一次训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/setuptools/depends.py:2: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "2021-04-12 21:32:38 [INFO]\t\n",
      "------------Environment Information-------------\n",
      "platform: Linux-4.4.0-150-generic-x86_64-with-debian-stretch-sid\n",
      "Python: 3.7.4 (default, Aug 13 2019, 20:35:49) [GCC 7.3.0]\n",
      "Paddle compiled with cuda: True\n",
      "NVCC: Cuda compilation tools, release 10.1, V10.1.243\n",
      "cudnn: 7.6\n",
      "GPUs used: 1\n",
      "CUDA_VISIBLE_DEVICES: None\n",
      "GPU: ['GPU 0: Tesla V100-SXM2-32GB']\n",
      "GCC: gcc (Ubuntu 7.5.0-3ubuntu1~16.04) 7.5.0\n",
      "PaddlePaddle: 2.0.1\n",
      "OpenCV: 4.1.1\n",
      "------------------------------------------------\n",
      "2021-04-12 21:32:39 [INFO]\t\n",
      "---------------Config Information---------------\n",
      "batch_size: 16\n",
      "iters: 10000\n",
      "learning_rate:\n",
      "  decay:\n",
      "    end_lr: 0\n",
      "    power: 0.9\n",
      "    type: poly\n",
      "  value: 0.01\n",
      "loss:\n",
      "  coef:\n",
      "  - 1\n",
      "  types:\n",
      "  - ignore_index: 255\n",
      "    type: CrossEntropyLoss\n",
      "model:\n",
      "  align_corners: false\n",
      "  aspp_out_channels: 256\n",
      "  aspp_ratios:\n",
      "  - 1\n",
      "  - 12\n",
      "  - 24\n",
      "  - 36\n",
      "  backbone:\n",
      "    multi_grid:\n",
      "    - 1\n",
      "    - 2\n",
      "    - 4\n",
      "    output_stride: 8\n",
      "    pretrained: https://bj.bcebos.com/paddleseg/dygraph/resnet50_vd_ssld_v2.tar.gz\n",
      "    type: ResNet50_vd\n",
      "  backbone_indices:\n",
      "  - 3\n",
      "  pretrained: null\n",
      "  type: DeepLabV3\n",
      "optimizer:\n",
      "  momentum: 0.9\n",
      "  type: sgd\n",
      "  weight_decay: 4.0e-05\n",
      "train_dataset:\n",
      "  dataset_root: /home/aistudio/\n",
      "  mode: train\n",
      "  num_classes: 4\n",
      "  train_path: /home/aistudio/train_list.txt\n",
      "  transforms:\n",
      "  - target_size:\n",
      "    - 256\n",
      "    - 256\n",
      "    type: Resize\n",
      "  - type: RandomHorizontalFlip\n",
      "  - type: Normalize\n",
      "  type: Dataset\n",
      "val_dataset:\n",
      "  dataset_root: /home/aistudio/\n",
      "  mode: val\n",
      "  num_classes: 4\n",
      "  transforms:\n",
      "  - target_size:\n",
      "    - 256\n",
      "    - 256\n",
      "    type: Resize\n",
      "  - type: Normalize\n",
      "  type: Dataset\n",
      "  val_path: /home/aistudio/val_list.txt\n",
      "------------------------------------------------\n",
      "W0412 21:32:39.731019 31384 device_context.cc:362] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 10.1, Runtime API Version: 10.1\n",
      "W0412 21:32:39.731081 31384 device_context.cc:372] device: 0, cuDNN Version: 7.6.\n",
      "2021-04-12 21:32:44 [INFO]\tLoading pretrained model from https://bj.bcebos.com/paddleseg/dygraph/resnet50_vd_ssld_v2.tar.gz\n",
      "2021-04-12 21:32:44,719 - INFO - Lock 139778941641936 acquired on /home/aistudio/.paddleseg/tmp/resnet50_vd_ssld_v2\n",
      "Connecting to https://bj.bcebos.com/paddleseg/dygraph/resnet50_vd_ssld_v2.tar.gz\n",
      "Downloading resnet50_vd_ssld_v2.tar.gz\n",
      "[==================================================] 100.00%\n",
      "Uncompress resnet50_vd_ssld_v2.tar.gz\n",
      "[==================================================] 100.00%\n",
      "2021-04-12 21:32:50,220 - INFO - Lock 139778941641936 released on /home/aistudio/.paddleseg/tmp/resnet50_vd_ssld_v2\n",
      "2021-04-12 21:32:51 [INFO]\tThere are 275/275 variables loaded into ResNet_vd.\n",
      "2021-04-12 21:33:03 [INFO]\t[TRAIN] epoch=1, iter=10/10000, loss=1.5626, lr=0.009992, batch_cost=1.2044, reader_cost=0.02279, ips=13.2852 samples/sec | ETA 03:20:31\n",
      "2021-04-12 21:33:15 [INFO]\t[TRAIN] epoch=1, iter=20/10000, loss=1.4735, lr=0.009983, batch_cost=1.1736, reader_cost=0.00014, ips=13.6330 samples/sec | ETA 03:15:12\n",
      "2021-04-12 21:33:27 [INFO]\t[TRAIN] epoch=1, iter=30/10000, loss=1.1406, lr=0.009974, batch_cost=1.1710, reader_cost=0.00013, ips=13.6636 samples/sec | ETA 03:14:34\n",
      "2021-04-12 21:33:38 [INFO]\t[TRAIN] epoch=1, iter=40/10000, loss=1.4919, lr=0.009965, batch_cost=1.1745, reader_cost=0.00014, ips=13.6230 samples/sec | ETA 03:14:57\n",
      "2021-04-12 21:33:50 [INFO]\t[TRAIN] epoch=1, iter=50/10000, loss=1.3800, lr=0.009956, batch_cost=1.1739, reader_cost=0.00014, ips=13.6297 samples/sec | ETA 03:14:40\n",
      "2021-04-12 21:34:02 [INFO]\t[TRAIN] epoch=1, iter=60/10000, loss=1.3415, lr=0.009947, batch_cost=1.1737, reader_cost=0.00013, ips=13.6322 samples/sec | ETA 03:14:26\n",
      "2021-04-12 21:34:14 [INFO]\t[TRAIN] epoch=1, iter=70/10000, loss=1.2383, lr=0.009938, batch_cost=1.1717, reader_cost=0.00013, ips=13.6559 samples/sec | ETA 03:13:54\n",
      "2021-04-12 21:34:25 [INFO]\t[TRAIN] epoch=1, iter=80/10000, loss=1.3776, lr=0.009929, batch_cost=1.1718, reader_cost=0.00013, ips=13.6546 samples/sec | ETA 03:13:43\n",
      "2021-04-12 21:34:37 [INFO]\t[TRAIN] epoch=1, iter=90/10000, loss=1.2136, lr=0.009920, batch_cost=1.1728, reader_cost=0.00013, ips=13.6429 samples/sec | ETA 03:13:42\n",
      "2021-04-12 21:34:49 [INFO]\t[TRAIN] epoch=1, iter=100/10000, loss=1.3265, lr=0.009911, batch_cost=1.1738, reader_cost=0.00015, ips=13.6305 samples/sec | ETA 03:13:40\n",
      "2021-04-12 21:35:01 [INFO]\t[TRAIN] epoch=1, iter=110/10000, loss=1.0993, lr=0.009902, batch_cost=1.1738, reader_cost=0.00013, ips=13.6306 samples/sec | ETA 03:13:29\n",
      "2021-04-12 21:35:12 [INFO]\t[TRAIN] epoch=1, iter=120/10000, loss=1.1183, lr=0.009893, batch_cost=1.1735, reader_cost=0.00013, ips=13.6343 samples/sec | ETA 03:13:14\n",
      "2021-04-12 21:35:24 [INFO]\t[TRAIN] epoch=1, iter=130/10000, loss=1.1832, lr=0.009884, batch_cost=1.1751, reader_cost=0.00014, ips=13.6161 samples/sec | ETA 03:13:18\n",
      "2021-04-12 21:35:36 [INFO]\t[TRAIN] epoch=1, iter=140/10000, loss=1.0882, lr=0.009875, batch_cost=1.1750, reader_cost=0.00013, ips=13.6171 samples/sec | ETA 03:13:05\n",
      "2021-04-12 21:35:47 [INFO]\t[TRAIN] epoch=1, iter=150/10000, loss=1.1702, lr=0.009866, batch_cost=1.1755, reader_cost=0.00014, ips=13.6110 samples/sec | ETA 03:12:58\n",
      "2021-04-12 21:35:59 [INFO]\t[TRAIN] epoch=1, iter=160/10000, loss=1.0392, lr=0.009857, batch_cost=1.1746, reader_cost=0.00013, ips=13.6212 samples/sec | ETA 03:12:38\n",
      "2021-04-12 21:36:11 [INFO]\t[TRAIN] epoch=1, iter=170/10000, loss=1.2013, lr=0.009848, batch_cost=1.1746, reader_cost=0.00013, ips=13.6222 samples/sec | ETA 03:12:25\n",
      "2021-04-12 21:36:23 [INFO]\t[TRAIN] epoch=1, iter=180/10000, loss=1.1993, lr=0.009839, batch_cost=1.1751, reader_cost=0.00013, ips=13.6160 samples/sec | ETA 03:12:19\n",
      "2021-04-12 21:36:34 [INFO]\t[TRAIN] epoch=1, iter=190/10000, loss=1.0704, lr=0.009830, batch_cost=1.1749, reader_cost=0.00013, ips=13.6187 samples/sec | ETA 03:12:05\n",
      "2021-04-12 21:36:46 [INFO]\t[TRAIN] epoch=1, iter=200/10000, loss=1.0742, lr=0.009821, batch_cost=1.1757, reader_cost=0.00013, ips=13.6085 samples/sec | ETA 03:12:02\n",
      "2021-04-12 21:36:58 [INFO]\t[TRAIN] epoch=1, iter=210/10000, loss=1.1194, lr=0.009812, batch_cost=1.1745, reader_cost=0.00013, ips=13.6224 samples/sec | ETA 03:11:38\n",
      "2021-04-12 21:37:10 [INFO]\t[TRAIN] epoch=1, iter=220/10000, loss=1.0566, lr=0.009803, batch_cost=1.1762, reader_cost=0.00014, ips=13.6026 samples/sec | ETA 03:11:43\n",
      "2021-04-12 21:37:22 [INFO]\t[TRAIN] epoch=1, iter=230/10000, loss=1.2775, lr=0.009794, batch_cost=1.1762, reader_cost=0.00013, ips=13.6036 samples/sec | ETA 03:11:31\n",
      "2021-04-12 21:37:33 [INFO]\t[TRAIN] epoch=1, iter=240/10000, loss=1.1447, lr=0.009785, batch_cost=1.1767, reader_cost=0.00013, ips=13.5971 samples/sec | ETA 03:11:24\n",
      "2021-04-12 21:37:45 [INFO]\t[TRAIN] epoch=1, iter=250/10000, loss=0.9744, lr=0.009776, batch_cost=1.1777, reader_cost=0.00012, ips=13.5853 samples/sec | ETA 03:11:23\n",
      "2021-04-12 21:37:45 [INFO]\tStart evaluating (total_samples=3333, total_iters=3333)...\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/math_op_patch.py:238: UserWarning: The dtype of left and right variables are not the same, left dtype is VarType.INT32, but right dtype is VarType.BOOL, the right dtype will convert to VarType.INT32\n",
      "  format(lhs_dtype, rhs_dtype, lhs_dtype))\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/math_op_patch.py:238: UserWarning: The dtype of left and right variables are not the same, left dtype is VarType.INT64, but right dtype is VarType.BOOL, the right dtype will convert to VarType.INT64\n",
      "  format(lhs_dtype, rhs_dtype, lhs_dtype))\n",
      "3333/3333 [==============================] - 96s 29ms/step - batch_cost: 0.0285 - reader cost: 5.8603e-\n",
      "2021-04-12 21:39:21 [INFO]\t[EVAL] #Images=3333 mIoU=0.3797 Acc=0.5715 Kappa=0.4064 \n",
      "2021-04-12 21:39:21 [INFO]\t[EVAL] Class IoU: \n",
      "[0.2999 0.6123 0.3592 0.2475]\n",
      "2021-04-12 21:39:21 [INFO]\t[EVAL] Class Acc: \n",
      "[0.4708 0.7482 0.5333 0.3926]\n",
      "2021-04-12 21:39:26 [INFO]\t[EVAL] The model with the best validation mIoU (0.3797) was saved at iter 250.\n",
      "2021-04-12 21:39:38 [INFO]\t[TRAIN] epoch=1, iter=260/10000, loss=1.0277, lr=0.009767, batch_cost=1.1768, reader_cost=0.00013, ips=13.5958 samples/sec | ETA 03:11:02\n",
      "2021-04-12 21:39:49 [INFO]\t[TRAIN] epoch=1, iter=270/10000, loss=1.1428, lr=0.009758, batch_cost=1.1749, reader_cost=0.00013, ips=13.6186 samples/sec | ETA 03:10:31\n",
      "2021-04-12 21:40:01 [INFO]\t[TRAIN] epoch=1, iter=280/10000, loss=1.1064, lr=0.009749, batch_cost=1.1751, reader_cost=0.00013, ips=13.6157 samples/sec | ETA 03:10:22\n",
      "2021-04-12 21:40:13 [INFO]\t[TRAIN] epoch=1, iter=290/10000, loss=0.9661, lr=0.009740, batch_cost=1.1761, reader_cost=0.00013, ips=13.6039 samples/sec | ETA 03:10:20\n",
      "2021-04-12 21:40:25 [INFO]\t[TRAIN] epoch=1, iter=300/10000, loss=1.0335, lr=0.009730, batch_cost=1.1753, reader_cost=0.00012, ips=13.6136 samples/sec | ETA 03:10:00\n",
      "2021-04-12 21:40:36 [INFO]\t[TRAIN] epoch=1, iter=310/10000, loss=1.0289, lr=0.009721, batch_cost=1.1759, reader_cost=0.00012, ips=13.6070 samples/sec | ETA 03:09:54\n",
      "2021-04-12 21:40:48 [INFO]\t[TRAIN] epoch=1, iter=320/10000, loss=1.1301, lr=0.009712, batch_cost=1.1762, reader_cost=0.00013, ips=13.6026 samples/sec | ETA 03:09:46\n",
      "2021-04-12 21:41:00 [INFO]\t[TRAIN] epoch=1, iter=330/10000, loss=1.0199, lr=0.009703, batch_cost=1.1761, reader_cost=0.00012, ips=13.6041 samples/sec | ETA 03:09:33\n",
      "2021-04-12 21:41:12 [INFO]\t[TRAIN] epoch=1, iter=340/10000, loss=1.0782, lr=0.009694, batch_cost=1.1771, reader_cost=0.00013, ips=13.5923 samples/sec | ETA 03:09:31\n",
      "2021-04-12 21:41:24 [INFO]\t[TRAIN] epoch=1, iter=350/10000, loss=1.0140, lr=0.009685, batch_cost=1.1765, reader_cost=0.00012, ips=13.5999 samples/sec | ETA 03:09:13\n",
      "2021-04-12 21:41:35 [INFO]\t[TRAIN] epoch=1, iter=360/10000, loss=1.0830, lr=0.009676, batch_cost=1.1764, reader_cost=0.00012, ips=13.6009 samples/sec | ETA 03:09:00\n",
      "2021-04-12 21:41:47 [INFO]\t[TRAIN] epoch=1, iter=370/10000, loss=1.0435, lr=0.009667, batch_cost=1.1782, reader_cost=0.00013, ips=13.5804 samples/sec | ETA 03:09:05\n",
      "2021-04-12 21:41:59 [INFO]\t[TRAIN] epoch=1, iter=380/10000, loss=0.9955, lr=0.009658, batch_cost=1.1778, reader_cost=0.00013, ips=13.5850 samples/sec | ETA 03:08:50\n",
      "2021-04-12 21:42:11 [INFO]\t[TRAIN] epoch=1, iter=390/10000, loss=1.0234, lr=0.009649, batch_cost=1.1764, reader_cost=0.00012, ips=13.6014 samples/sec | ETA 03:08:24\n",
      "2021-04-12 21:42:22 [INFO]\t[TRAIN] epoch=1, iter=400/10000, loss=1.1103, lr=0.009640, batch_cost=1.1775, reader_cost=0.00012, ips=13.5880 samples/sec | ETA 03:08:24\n",
      "2021-04-12 21:42:34 [INFO]\t[TRAIN] epoch=1, iter=410/10000, loss=1.0329, lr=0.009631, batch_cost=1.1769, reader_cost=0.00012, ips=13.5947 samples/sec | ETA 03:08:06\n",
      "2021-04-12 21:42:46 [INFO]\t[TRAIN] epoch=1, iter=420/10000, loss=0.9360, lr=0.009622, batch_cost=1.1761, reader_cost=0.00012, ips=13.6038 samples/sec | ETA 03:07:47\n",
      "2021-04-12 21:42:58 [INFO]\t[TRAIN] epoch=1, iter=430/10000, loss=0.9836, lr=0.009613, batch_cost=1.1770, reader_cost=0.00012, ips=13.5943 samples/sec | ETA 03:07:43\n",
      "2021-04-12 21:43:09 [INFO]\t[TRAIN] epoch=1, iter=440/10000, loss=1.0230, lr=0.009604, batch_cost=1.1766, reader_cost=0.00012, ips=13.5979 samples/sec | ETA 03:07:28\n",
      "2021-04-12 21:43:21 [INFO]\t[TRAIN] epoch=1, iter=450/10000, loss=0.9496, lr=0.009595, batch_cost=1.1748, reader_cost=0.00013, ips=13.6189 samples/sec | ETA 03:06:59\n",
      "2021-04-12 21:43:33 [INFO]\t[TRAIN] epoch=1, iter=460/10000, loss=1.0330, lr=0.009586, batch_cost=1.1752, reader_cost=0.00012, ips=13.6142 samples/sec | ETA 03:06:51\n",
      "2021-04-12 21:43:45 [INFO]\t[TRAIN] epoch=1, iter=470/10000, loss=1.1609, lr=0.009577, batch_cost=1.1752, reader_cost=0.00013, ips=13.6147 samples/sec | ETA 03:06:39\n",
      "2021-04-12 21:43:56 [INFO]\t[TRAIN] epoch=1, iter=480/10000, loss=1.0139, lr=0.009568, batch_cost=1.1756, reader_cost=0.00014, ips=13.6106 samples/sec | ETA 03:06:31\n",
      "2021-04-12 21:44:08 [INFO]\t[TRAIN] epoch=1, iter=490/10000, loss=0.8933, lr=0.009559, batch_cost=1.1748, reader_cost=0.00014, ips=13.6199 samples/sec | ETA 03:06:11\n",
      "2021-04-12 21:44:20 [INFO]\t[TRAIN] epoch=1, iter=500/10000, loss=1.0113, lr=0.009550, batch_cost=1.1753, reader_cost=0.00015, ips=13.6134 samples/sec | ETA 03:06:05\n",
      "2021-04-12 21:44:20 [INFO]\tStart evaluating (total_samples=3333, total_iters=3333)...\n",
      "3333/3333 [==============================] - 95s 29ms/step - batch_cost: 0.0284 - reader cost: 5.8009e-0\n",
      "2021-04-12 21:45:55 [INFO]\t[EVAL] #Images=3333 mIoU=0.3860 Acc=0.5978 Kappa=0.4282 \n",
      "2021-04-12 21:45:55 [INFO]\t[EVAL] Class IoU: \n",
      "[0.322  0.6252 0.3855 0.2115]\n",
      "2021-04-12 21:45:55 [INFO]\t[EVAL] Class Acc: \n",
      "[0.5026 0.6793 0.5993 0.4739]\n",
      "2021-04-12 21:46:01 [INFO]\t[EVAL] The model with the best validation mIoU (0.3860) was saved at iter 500.\n",
      "2021-04-12 21:46:12 [INFO]\t[TRAIN] epoch=1, iter=510/10000, loss=1.1314, lr=0.009541, batch_cost=1.1743, reader_cost=0.00013, ips=13.6250 samples/sec | ETA 03:05:44\n",
      "2021-04-12 21:46:24 [INFO]\t[TRAIN] epoch=1, iter=520/10000, loss=1.0540, lr=0.009532, batch_cost=1.1726, reader_cost=0.00013, ips=13.6454 samples/sec | ETA 03:05:15\n",
      "2021-04-12 21:46:36 [INFO]\t[TRAIN] epoch=1, iter=530/10000, loss=1.0318, lr=0.009523, batch_cost=1.1730, reader_cost=0.00013, ips=13.6403 samples/sec | ETA 03:05:08\n",
      "2021-04-12 21:46:48 [INFO]\t[TRAIN] epoch=1, iter=540/10000, loss=1.0236, lr=0.009514, batch_cost=1.1737, reader_cost=0.00014, ips=13.6321 samples/sec | ETA 03:05:03\n",
      "2021-04-12 21:46:59 [INFO]\t[TRAIN] epoch=1, iter=550/10000, loss=0.9499, lr=0.009505, batch_cost=1.1746, reader_cost=0.00014, ips=13.6218 samples/sec | ETA 03:04:59\n",
      "2021-04-12 21:47:11 [INFO]\t[TRAIN] epoch=1, iter=560/10000, loss=0.9221, lr=0.009495, batch_cost=1.1748, reader_cost=0.00014, ips=13.6192 samples/sec | ETA 03:04:50\n",
      "2021-04-12 21:47:23 [INFO]\t[TRAIN] epoch=1, iter=570/10000, loss=1.0198, lr=0.009486, batch_cost=1.1751, reader_cost=0.00014, ips=13.6155 samples/sec | ETA 03:04:41\n",
      "2021-04-12 21:47:35 [INFO]\t[TRAIN] epoch=1, iter=580/10000, loss=1.0192, lr=0.009477, batch_cost=1.1748, reader_cost=0.00014, ips=13.6196 samples/sec | ETA 03:04:26\n",
      "2021-04-12 21:47:46 [INFO]\t[TRAIN] epoch=1, iter=590/10000, loss=0.9563, lr=0.009468, batch_cost=1.1760, reader_cost=0.00014, ips=13.6050 samples/sec | ETA 03:04:26\n",
      "2021-04-12 21:47:58 [INFO]\t[TRAIN] epoch=1, iter=600/10000, loss=0.9509, lr=0.009459, batch_cost=1.1770, reader_cost=0.00013, ips=13.5937 samples/sec | ETA 03:04:23\n",
      "2021-04-12 21:48:10 [INFO]\t[TRAIN] epoch=1, iter=610/10000, loss=0.8545, lr=0.009450, batch_cost=1.1772, reader_cost=0.00013, ips=13.5921 samples/sec | ETA 03:04:13\n",
      "2021-04-12 21:48:22 [INFO]\t[TRAIN] epoch=1, iter=620/10000, loss=0.8624, lr=0.009441, batch_cost=1.1790, reader_cost=0.00013, ips=13.5705 samples/sec | ETA 03:04:19\n",
      "2021-04-12 21:48:33 [INFO]\t[TRAIN] epoch=1, iter=630/10000, loss=0.9267, lr=0.009432, batch_cost=1.1788, reader_cost=0.00014, ips=13.5730 samples/sec | ETA 03:04:05\n",
      "2021-04-12 21:48:45 [INFO]\t[TRAIN] epoch=1, iter=640/10000, loss=0.8396, lr=0.009423, batch_cost=1.1786, reader_cost=0.00013, ips=13.5755 samples/sec | ETA 03:03:51\n",
      "2021-04-12 21:48:57 [INFO]\t[TRAIN] epoch=1, iter=650/10000, loss=0.9447, lr=0.009414, batch_cost=1.1795, reader_cost=0.00013, ips=13.5651 samples/sec | ETA 03:03:48\n",
      "2021-04-12 21:49:09 [INFO]\t[TRAIN] epoch=1, iter=660/10000, loss=1.0203, lr=0.009405, batch_cost=1.1809, reader_cost=0.00013, ips=13.5485 samples/sec | ETA 03:03:50\n",
      "2021-04-12 21:49:21 [INFO]\t[TRAIN] epoch=1, iter=670/10000, loss=0.9536, lr=0.009396, batch_cost=1.1790, reader_cost=0.00013, ips=13.5705 samples/sec | ETA 03:03:20\n",
      "2021-04-12 21:49:32 [INFO]\t[TRAIN] epoch=1, iter=680/10000, loss=1.0035, lr=0.009387, batch_cost=1.1803, reader_cost=0.00013, ips=13.5560 samples/sec | ETA 03:03:20\n",
      "2021-04-12 21:49:44 [INFO]\t[TRAIN] epoch=1, iter=690/10000, loss=0.9968, lr=0.009378, batch_cost=1.1799, reader_cost=0.00013, ips=13.5609 samples/sec | ETA 03:03:04\n",
      "2021-04-12 21:49:56 [INFO]\t[TRAIN] epoch=1, iter=700/10000, loss=0.9674, lr=0.009369, batch_cost=1.1809, reader_cost=0.00013, ips=13.5495 samples/sec | ETA 03:03:01\n",
      "2021-04-12 21:50:08 [INFO]\t[TRAIN] epoch=1, iter=710/10000, loss=0.8814, lr=0.009360, batch_cost=1.1814, reader_cost=0.00014, ips=13.5431 samples/sec | ETA 03:02:55\n",
      "2021-04-12 21:50:20 [INFO]\t[TRAIN] epoch=1, iter=720/10000, loss=0.7564, lr=0.009351, batch_cost=1.1818, reader_cost=0.00014, ips=13.5390 samples/sec | ETA 03:02:46\n",
      "2021-04-12 21:50:31 [INFO]\t[TRAIN] epoch=1, iter=730/10000, loss=0.9309, lr=0.009341, batch_cost=1.1821, reader_cost=0.00013, ips=13.5352 samples/sec | ETA 03:02:38\n",
      "2021-04-12 21:50:43 [INFO]\t[TRAIN] epoch=1, iter=740/10000, loss=1.0005, lr=0.009332, batch_cost=1.1802, reader_cost=0.00013, ips=13.5570 samples/sec | ETA 03:02:08\n",
      "2021-04-12 21:50:55 [INFO]\t[TRAIN] epoch=1, iter=750/10000, loss=0.9587, lr=0.009323, batch_cost=1.1803, reader_cost=0.00014, ips=13.5556 samples/sec | ETA 03:01:57\n",
      "2021-04-12 21:50:55 [INFO]\tStart evaluating (total_samples=3333, total_iters=3333)...\n",
      "3333/3333 [==============================] - 100s 30ms/step - batch_cost: 0.0298 - reader cost: 6.9524e-0\n",
      "2021-04-12 21:52:35 [INFO]\t[EVAL] #Images=3333 mIoU=0.3932 Acc=0.6290 Kappa=0.4714 \n",
      "2021-04-12 21:52:35 [INFO]\t[EVAL] Class IoU: \n",
      "[0.4283 0.673  0.4198 0.0515]\n",
      "2021-04-12 21:52:35 [INFO]\t[EVAL] Class Acc: \n",
      "[0.5067 0.788  0.5823 0.7265]\n",
      "2021-04-12 21:52:41 [INFO]\t[EVAL] The model with the best validation mIoU (0.3932) was saved at iter 750.\n",
      "2021-04-12 21:52:52 [INFO]\t[TRAIN] epoch=1, iter=760/10000, loss=0.8828, lr=0.009314, batch_cost=1.1783, reader_cost=0.00014, ips=13.5793 samples/sec | ETA 03:01:27\n",
      "2021-04-12 21:53:04 [INFO]\t[TRAIN] epoch=1, iter=770/10000, loss=1.0074, lr=0.009305, batch_cost=1.1747, reader_cost=0.00013, ips=13.6202 samples/sec | ETA 03:00:42\n",
      "2021-04-12 21:53:16 [INFO]\t[TRAIN] epoch=1, iter=780/10000, loss=0.8785, lr=0.009296, batch_cost=1.1762, reader_cost=0.00015, ips=13.6032 samples/sec | ETA 03:00:44\n",
      "2021-04-12 21:53:28 [INFO]\t[TRAIN] epoch=1, iter=790/10000, loss=0.9848, lr=0.009287, batch_cost=1.1744, reader_cost=0.00014, ips=13.6242 samples/sec | ETA 03:00:16\n",
      "2021-04-12 21:53:39 [INFO]\t[TRAIN] epoch=1, iter=800/10000, loss=0.9438, lr=0.009278, batch_cost=1.1745, reader_cost=0.00013, ips=13.6227 samples/sec | ETA 03:00:05\n",
      "2021-04-12 21:53:51 [INFO]\t[TRAIN] epoch=1, iter=810/10000, loss=0.9501, lr=0.009269, batch_cost=1.1747, reader_cost=0.00013, ips=13.6209 samples/sec | ETA 02:59:55\n",
      "2021-04-12 21:54:03 [INFO]\t[TRAIN] epoch=1, iter=820/10000, loss=0.9319, lr=0.009260, batch_cost=1.1772, reader_cost=0.00014, ips=13.5912 samples/sec | ETA 03:00:06\n",
      "2021-04-12 21:54:15 [INFO]\t[TRAIN] epoch=1, iter=830/10000, loss=0.7788, lr=0.009251, batch_cost=1.1761, reader_cost=0.00014, ips=13.6042 samples/sec | ETA 02:59:44\n",
      "2021-04-12 21:54:26 [INFO]\t[TRAIN] epoch=1, iter=840/10000, loss=0.9982, lr=0.009242, batch_cost=1.1750, reader_cost=0.00013, ips=13.6172 samples/sec | ETA 02:59:22\n",
      "2021-04-12 21:54:38 [INFO]\t[TRAIN] epoch=1, iter=850/10000, loss=0.8724, lr=0.009233, batch_cost=1.1752, reader_cost=0.00013, ips=13.6149 samples/sec | ETA 02:59:12\n",
      "2021-04-12 21:54:50 [INFO]\t[TRAIN] epoch=1, iter=860/10000, loss=0.9384, lr=0.009223, batch_cost=1.1737, reader_cost=0.00013, ips=13.6326 samples/sec | ETA 02:58:47\n",
      "2021-04-12 21:55:02 [INFO]\t[TRAIN] epoch=1, iter=870/10000, loss=1.0180, lr=0.009214, batch_cost=1.1745, reader_cost=0.00013, ips=13.6229 samples/sec | ETA 02:58:43\n",
      "2021-04-12 21:55:13 [INFO]\t[TRAIN] epoch=1, iter=880/10000, loss=0.9566, lr=0.009205, batch_cost=1.1755, reader_cost=0.00013, ips=13.6117 samples/sec | ETA 02:58:40\n",
      "2021-04-12 21:55:25 [INFO]\t[TRAIN] epoch=1, iter=890/10000, loss=0.9182, lr=0.009196, batch_cost=1.1745, reader_cost=0.00013, ips=13.6227 samples/sec | ETA 02:58:19\n",
      "2021-04-12 21:55:37 [INFO]\t[TRAIN] epoch=1, iter=900/10000, loss=0.8862, lr=0.009187, batch_cost=1.1755, reader_cost=0.00014, ips=13.6112 samples/sec | ETA 02:58:17\n",
      "2021-04-12 21:55:49 [INFO]\t[TRAIN] epoch=1, iter=910/10000, loss=0.9290, lr=0.009178, batch_cost=1.1754, reader_cost=0.00013, ips=13.6129 samples/sec | ETA 02:58:03\n",
      "2021-04-12 21:56:00 [INFO]\t[TRAIN] epoch=1, iter=920/10000, loss=0.8479, lr=0.009169, batch_cost=1.1752, reader_cost=0.00014, ips=13.6142 samples/sec | ETA 02:57:51\n",
      "2021-04-12 21:56:12 [INFO]\t[TRAIN] epoch=1, iter=930/10000, loss=0.9903, lr=0.009160, batch_cost=1.1752, reader_cost=0.00014, ips=13.6145 samples/sec | ETA 02:57:39\n",
      "2021-04-12 21:56:24 [INFO]\t[TRAIN] epoch=1, iter=940/10000, loss=0.8705, lr=0.009151, batch_cost=1.1757, reader_cost=0.00014, ips=13.6093 samples/sec | ETA 02:57:31\n",
      "2021-04-12 21:56:36 [INFO]\t[TRAIN] epoch=1, iter=950/10000, loss=0.9261, lr=0.009142, batch_cost=1.1761, reader_cost=0.00013, ips=13.6042 samples/sec | ETA 02:57:23\n",
      "2021-04-12 21:56:47 [INFO]\t[TRAIN] epoch=1, iter=960/10000, loss=0.8991, lr=0.009133, batch_cost=1.1769, reader_cost=0.00014, ips=13.5953 samples/sec | ETA 02:57:18\n",
      "2021-04-12 21:56:59 [INFO]\t[TRAIN] epoch=1, iter=970/10000, loss=0.9552, lr=0.009124, batch_cost=1.1742, reader_cost=0.00014, ips=13.6260 samples/sec | ETA 02:56:43\n",
      "2021-04-12 21:57:11 [INFO]\t[TRAIN] epoch=1, iter=980/10000, loss=1.0468, lr=0.009114, batch_cost=1.1754, reader_cost=0.00014, ips=13.6122 samples/sec | ETA 02:56:42\n",
      "2021-04-12 21:57:23 [INFO]\t[TRAIN] epoch=1, iter=990/10000, loss=0.9231, lr=0.009105, batch_cost=1.1781, reader_cost=0.00013, ips=13.5816 samples/sec | ETA 02:56:54\n",
      "2021-04-12 21:57:34 [INFO]\t[TRAIN] epoch=1, iter=1000/10000, loss=0.8725, lr=0.009096, batch_cost=1.1751, reader_cost=0.00013, ips=13.6163 samples/sec | ETA 02:56:15\n",
      "2021-04-12 21:57:35 [INFO]\tStart evaluating (total_samples=3333, total_iters=3333)...\n",
      "3333/3333 [==============================] - 103s 31ms/step - batch_cost: 0.0307 - reader cost: 7.5858e-05\n",
      "2021-04-12 21:59:17 [INFO]\t[EVAL] #Images=3333 mIoU=0.4309 Acc=0.6323 Kappa=0.4853 \n",
      "2021-04-12 21:59:17 [INFO]\t[EVAL] Class IoU: \n",
      "[0.4052 0.665  0.4358 0.2176]\n",
      "2021-04-12 21:59:17 [INFO]\t[EVAL] Class Acc: \n",
      "[0.5072 0.8254 0.5904 0.5297]\n",
      "2021-04-12 21:59:23 [INFO]\t[EVAL] The model with the best validation mIoU (0.4309) was saved at iter 1000.\n",
      "2021-04-12 21:59:35 [INFO]\t[TRAIN] epoch=1, iter=1010/10000, loss=0.9802, lr=0.009087, batch_cost=1.1856, reader_cost=0.00012, ips=13.4948 samples/sec | ETA 02:57:38\n",
      "2021-04-12 21:59:47 [INFO]\t[TRAIN] epoch=1, iter=1020/10000, loss=0.9580, lr=0.009078, batch_cost=1.1851, reader_cost=0.00014, ips=13.5011 samples/sec | ETA 02:57:22\n",
      "2021-04-12 21:59:58 [INFO]\t[TRAIN] epoch=1, iter=1030/10000, loss=1.0609, lr=0.009069, batch_cost=1.1874, reader_cost=0.00015, ips=13.4749 samples/sec | ETA 02:57:30\n",
      "2021-04-12 22:00:10 [INFO]\t[TRAIN] epoch=1, iter=1040/10000, loss=0.8845, lr=0.009060, batch_cost=1.1856, reader_cost=0.00014, ips=13.4957 samples/sec | ETA 02:57:02\n",
      "2021-04-12 22:00:22 [INFO]\t[TRAIN] epoch=1, iter=1050/10000, loss=1.0174, lr=0.009051, batch_cost=1.1866, reader_cost=0.00014, ips=13.4844 samples/sec | ETA 02:56:59\n",
      "2021-04-12 22:00:34 [INFO]\t[TRAIN] epoch=1, iter=1060/10000, loss=0.8871, lr=0.009042, batch_cost=1.1860, reader_cost=0.00014, ips=13.4912 samples/sec | ETA 02:56:42\n",
      "2021-04-12 22:00:46 [INFO]\t[TRAIN] epoch=1, iter=1070/10000, loss=0.8671, lr=0.009033, batch_cost=1.1861, reader_cost=0.00013, ips=13.4898 samples/sec | ETA 02:56:31\n",
      "2021-04-12 22:00:58 [INFO]\t[TRAIN] epoch=1, iter=1080/10000, loss=0.9018, lr=0.009023, batch_cost=1.1858, reader_cost=0.00013, ips=13.4924 samples/sec | ETA 02:56:17\n",
      "2021-04-12 22:01:10 [INFO]\t[TRAIN] epoch=1, iter=1090/10000, loss=0.8471, lr=0.009014, batch_cost=1.1856, reader_cost=0.00013, ips=13.4952 samples/sec | ETA 02:56:03\n",
      "2021-04-12 22:01:22 [INFO]\t[TRAIN] epoch=1, iter=1100/10000, loss=0.8681, lr=0.009005, batch_cost=1.1869, reader_cost=0.00013, ips=13.4802 samples/sec | ETA 02:56:03\n",
      "2021-04-12 22:01:33 [INFO]\t[TRAIN] epoch=1, iter=1110/10000, loss=0.7038, lr=0.008996, batch_cost=1.1869, reader_cost=0.00013, ips=13.4800 samples/sec | ETA 02:55:51\n",
      "2021-04-12 22:01:45 [INFO]\t[TRAIN] epoch=1, iter=1120/10000, loss=0.9552, lr=0.008987, batch_cost=1.1862, reader_cost=0.00012, ips=13.4880 samples/sec | ETA 02:55:33\n",
      "2021-04-12 22:01:57 [INFO]\t[TRAIN] epoch=1, iter=1130/10000, loss=0.9245, lr=0.008978, batch_cost=1.1869, reader_cost=0.00012, ips=13.4806 samples/sec | ETA 02:55:27\n",
      "2021-04-12 22:02:09 [INFO]\t[TRAIN] epoch=1, iter=1140/10000, loss=0.9683, lr=0.008969, batch_cost=1.1869, reader_cost=0.00013, ips=13.4802 samples/sec | ETA 02:55:16\n",
      "2021-04-12 22:02:21 [INFO]\t[TRAIN] epoch=1, iter=1150/10000, loss=0.9163, lr=0.008960, batch_cost=1.1859, reader_cost=0.00013, ips=13.4919 samples/sec | ETA 02:54:55\n",
      "2021-04-12 22:02:33 [INFO]\t[TRAIN] epoch=1, iter=1160/10000, loss=0.8984, lr=0.008951, batch_cost=1.1874, reader_cost=0.00013, ips=13.4750 samples/sec | ETA 02:54:56\n",
      "2021-04-12 22:02:45 [INFO]\t[TRAIN] epoch=1, iter=1170/10000, loss=0.9033, lr=0.008941, batch_cost=1.1863, reader_cost=0.00013, ips=13.4875 samples/sec | ETA 02:54:34\n",
      "2021-04-12 22:02:56 [INFO]\t[TRAIN] epoch=1, iter=1180/10000, loss=1.0423, lr=0.008932, batch_cost=1.1869, reader_cost=0.00013, ips=13.4802 samples/sec | ETA 02:54:28\n",
      "2021-04-12 22:03:08 [INFO]\t[TRAIN] epoch=1, iter=1190/10000, loss=0.8980, lr=0.008923, batch_cost=1.1862, reader_cost=0.00013, ips=13.4884 samples/sec | ETA 02:54:10\n",
      "2021-04-12 22:03:20 [INFO]\t[TRAIN] epoch=1, iter=1200/10000, loss=0.8500, lr=0.008914, batch_cost=1.1864, reader_cost=0.00012, ips=13.4865 samples/sec | ETA 02:54:00\n",
      "2021-04-12 22:03:32 [INFO]\t[TRAIN] epoch=1, iter=1210/10000, loss=0.9489, lr=0.008905, batch_cost=1.1863, reader_cost=0.00013, ips=13.4876 samples/sec | ETA 02:53:47\n",
      "2021-04-12 22:03:44 [INFO]\t[TRAIN] epoch=1, iter=1220/10000, loss=0.9831, lr=0.008896, batch_cost=1.1867, reader_cost=0.00013, ips=13.4827 samples/sec | ETA 02:53:39\n",
      "2021-04-12 22:03:56 [INFO]\t[TRAIN] epoch=1, iter=1230/10000, loss=0.8546, lr=0.008887, batch_cost=1.1866, reader_cost=0.00012, ips=13.4844 samples/sec | ETA 02:53:26\n",
      "2021-04-12 22:04:08 [INFO]\t[TRAIN] epoch=1, iter=1240/10000, loss=0.9117, lr=0.008878, batch_cost=1.1859, reader_cost=0.00012, ips=13.4920 samples/sec | ETA 02:53:08\n",
      "2021-04-12 22:04:19 [INFO]\t[TRAIN] epoch=1, iter=1250/10000, loss=0.9496, lr=0.008869, batch_cost=1.1860, reader_cost=0.00014, ips=13.4906 samples/sec | ETA 02:52:57\n",
      "2021-04-12 22:04:20 [INFO]\tStart evaluating (total_samples=3333, total_iters=3333)...\n",
      "3333/3333 [==============================] - 97s 29ms/step - batch_cost: 0.0291 - reader cost: 5.8225e-0\n",
      "2021-04-12 22:05:57 [INFO]\t[EVAL] #Images=3333 mIoU=0.4174 Acc=0.6227 Kappa=0.4671 \n",
      "2021-04-12 22:05:57 [INFO]\t[EVAL] Class IoU: \n",
      "[0.4297 0.6245 0.3769 0.2387]\n",
      "2021-04-12 22:05:57 [INFO]\t[EVAL] Class Acc: \n",
      "[0.4846 0.8323 0.6665 0.5843]\n",
      "2021-04-12 22:06:00 [INFO]\t[EVAL] The model with the best validation mIoU (0.4309) was saved at iter 1000.\n",
      "2021-04-12 22:06:12 [INFO]\t[TRAIN] epoch=1, iter=1260/10000, loss=0.9847, lr=0.008859, batch_cost=1.1742, reader_cost=0.00013, ips=13.6265 samples/sec | ETA 02:51:02\n",
      "2021-04-12 22:06:24 [INFO]\t[TRAIN] epoch=1, iter=1270/10000, loss=0.8629, lr=0.008850, batch_cost=1.1715, reader_cost=0.00012, ips=13.6579 samples/sec | ETA 02:50:27\n",
      "2021-04-12 22:06:36 [INFO]\t[TRAIN] epoch=1, iter=1280/10000, loss=0.9433, lr=0.008841, batch_cost=1.1739, reader_cost=0.00012, ips=13.6293 samples/sec | ETA 02:50:36\n",
      "2021-04-12 22:06:47 [INFO]\t[TRAIN] epoch=1, iter=1290/10000, loss=0.9632, lr=0.008832, batch_cost=1.1744, reader_cost=0.00013, ips=13.6242 samples/sec | ETA 02:50:28\n",
      "2021-04-12 22:06:59 [INFO]\t[TRAIN] epoch=1, iter=1300/10000, loss=0.9510, lr=0.008823, batch_cost=1.1735, reader_cost=0.00011, ips=13.6348 samples/sec | ETA 02:50:09\n",
      "2021-04-12 22:07:11 [INFO]\t[TRAIN] epoch=1, iter=1310/10000, loss=0.8107, lr=0.008814, batch_cost=1.1745, reader_cost=0.00012, ips=13.6227 samples/sec | ETA 02:50:06\n",
      "2021-04-12 22:07:23 [INFO]\t[TRAIN] epoch=1, iter=1320/10000, loss=0.9455, lr=0.008805, batch_cost=1.1746, reader_cost=0.00013, ips=13.6213 samples/sec | ETA 02:49:55\n",
      "2021-04-12 22:07:34 [INFO]\t[TRAIN] epoch=1, iter=1330/10000, loss=0.9123, lr=0.008796, batch_cost=1.1748, reader_cost=0.00012, ips=13.6198 samples/sec | ETA 02:49:45\n",
      "2021-04-12 22:07:46 [INFO]\t[TRAIN] epoch=1, iter=1340/10000, loss=0.9014, lr=0.008786, batch_cost=1.1739, reader_cost=0.00012, ips=13.6294 samples/sec | ETA 02:49:26\n",
      "2021-04-12 22:07:58 [INFO]\t[TRAIN] epoch=1, iter=1350/10000, loss=0.9028, lr=0.008777, batch_cost=1.1753, reader_cost=0.00011, ips=13.6135 samples/sec | ETA 02:49:26\n",
      "2021-04-12 22:08:10 [INFO]\t[TRAIN] epoch=1, iter=1360/10000, loss=0.7626, lr=0.008768, batch_cost=1.1745, reader_cost=0.00012, ips=13.6227 samples/sec | ETA 02:49:07\n",
      "2021-04-12 22:08:21 [INFO]\t[TRAIN] epoch=1, iter=1370/10000, loss=0.8755, lr=0.008759, batch_cost=1.1750, reader_cost=0.00012, ips=13.6170 samples/sec | ETA 02:49:00\n",
      "2021-04-12 22:08:33 [INFO]\t[TRAIN] epoch=1, iter=1380/10000, loss=0.8815, lr=0.008750, batch_cost=1.1752, reader_cost=0.00013, ips=13.6148 samples/sec | ETA 02:48:50\n",
      "2021-04-12 22:08:45 [INFO]\t[TRAIN] epoch=1, iter=1390/10000, loss=0.8771, lr=0.008741, batch_cost=1.1755, reader_cost=0.00012, ips=13.6116 samples/sec | ETA 02:48:40\n",
      "2021-04-12 22:08:57 [INFO]\t[TRAIN] epoch=1, iter=1400/10000, loss=0.8252, lr=0.008732, batch_cost=1.1759, reader_cost=0.00012, ips=13.6065 samples/sec | ETA 02:48:32\n",
      "2021-04-12 22:09:08 [INFO]\t[TRAIN] epoch=1, iter=1410/10000, loss=0.8520, lr=0.008722, batch_cost=1.1760, reader_cost=0.00012, ips=13.6051 samples/sec | ETA 02:48:22\n",
      "2021-04-12 22:09:20 [INFO]\t[TRAIN] epoch=1, iter=1420/10000, loss=0.8529, lr=0.008713, batch_cost=1.1753, reader_cost=0.00012, ips=13.6131 samples/sec | ETA 02:48:04\n",
      "2021-04-12 22:09:32 [INFO]\t[TRAIN] epoch=1, iter=1430/10000, loss=0.8383, lr=0.008704, batch_cost=1.1755, reader_cost=0.00013, ips=13.6115 samples/sec | ETA 02:47:53\n",
      "2021-04-12 22:09:44 [INFO]\t[TRAIN] epoch=1, iter=1440/10000, loss=0.8184, lr=0.008695, batch_cost=1.1757, reader_cost=0.00012, ips=13.6087 samples/sec | ETA 02:47:44\n",
      "2021-04-12 22:09:55 [INFO]\t[TRAIN] epoch=1, iter=1450/10000, loss=0.8500, lr=0.008686, batch_cost=1.1767, reader_cost=0.00012, ips=13.5969 samples/sec | ETA 02:47:41\n",
      "2021-04-12 22:10:07 [INFO]\t[TRAIN] epoch=1, iter=1460/10000, loss=0.8038, lr=0.008677, batch_cost=1.1753, reader_cost=0.00012, ips=13.6131 samples/sec | ETA 02:47:17\n",
      "2021-04-12 22:10:19 [INFO]\t[TRAIN] epoch=1, iter=1470/10000, loss=0.8504, lr=0.008668, batch_cost=1.1759, reader_cost=0.00012, ips=13.6062 samples/sec | ETA 02:47:10\n",
      "2021-04-12 22:10:31 [INFO]\t[TRAIN] epoch=1, iter=1480/10000, loss=0.8239, lr=0.008658, batch_cost=1.1764, reader_cost=0.00013, ips=13.6005 samples/sec | ETA 02:47:03\n",
      "2021-04-12 22:10:43 [INFO]\t[TRAIN] epoch=1, iter=1490/10000, loss=0.7876, lr=0.008649, batch_cost=1.1783, reader_cost=0.00012, ips=13.5794 samples/sec | ETA 02:47:06\n",
      "2021-04-12 22:10:54 [INFO]\t[TRAIN] epoch=1, iter=1500/10000, loss=0.7243, lr=0.008640, batch_cost=1.1757, reader_cost=0.00012, ips=13.6091 samples/sec | ETA 02:46:33\n",
      "2021-04-12 22:10:54 [INFO]\tStart evaluating (total_samples=3333, total_iters=3333)...\n",
      "3333/3333 [==============================] - 95s 28ms/step - batch_cost: 0.0282 - reader cost: 5.4517e-0\n",
      "2021-04-12 22:12:29 [INFO]\t[EVAL] #Images=3333 mIoU=0.4526 Acc=0.6614 Kappa=0.5184 \n",
      "2021-04-12 22:12:29 [INFO]\t[EVAL] Class IoU: \n",
      "[0.4436 0.6702 0.4198 0.2766]\n",
      "2021-04-12 22:12:29 [INFO]\t[EVAL] Class Acc: \n",
      "[0.5796 0.7327 0.7277 0.5539]\n",
      "2021-04-12 22:12:34 [INFO]\t[EVAL] The model with the best validation mIoU (0.4526) was saved at iter 1500.\n",
      "2021-04-12 22:12:46 [INFO]\t[TRAIN] epoch=1, iter=1510/10000, loss=0.7853, lr=0.008631, batch_cost=1.1860, reader_cost=0.00012, ips=13.4905 samples/sec | ETA 02:47:49\n",
      "2021-04-12 22:12:58 [INFO]\t[TRAIN] epoch=1, iter=1520/10000, loss=0.7678, lr=0.008622, batch_cost=1.1821, reader_cost=0.00012, ips=13.5354 samples/sec | ETA 02:47:04\n",
      "2021-04-12 22:13:10 [INFO]\t[TRAIN] epoch=1, iter=1530/10000, loss=0.8582, lr=0.008613, batch_cost=1.1832, reader_cost=0.00011, ips=13.5229 samples/sec | ETA 02:47:01\n",
      "2021-04-12 22:13:21 [INFO]\t[TRAIN] epoch=1, iter=1540/10000, loss=0.7684, lr=0.008604, batch_cost=1.1841, reader_cost=0.00012, ips=13.5119 samples/sec | ETA 02:46:57\n",
      "2021-04-12 22:13:33 [INFO]\t[TRAIN] epoch=1, iter=1550/10000, loss=0.8419, lr=0.008594, batch_cost=1.1851, reader_cost=0.00012, ips=13.5012 samples/sec | ETA 02:46:53\n",
      "2021-04-12 22:13:45 [INFO]\t[TRAIN] epoch=1, iter=1560/10000, loss=0.8915, lr=0.008585, batch_cost=1.1847, reader_cost=0.00012, ips=13.5058 samples/sec | ETA 02:46:38\n",
      "2021-04-12 22:13:57 [INFO]\t[TRAIN] epoch=1, iter=1570/10000, loss=0.9239, lr=0.008576, batch_cost=1.1843, reader_cost=0.00011, ips=13.5102 samples/sec | ETA 02:46:23\n",
      "2021-04-12 22:14:09 [INFO]\t[TRAIN] epoch=1, iter=1580/10000, loss=0.8706, lr=0.008567, batch_cost=1.1838, reader_cost=0.00012, ips=13.5158 samples/sec | ETA 02:46:07\n",
      "2021-04-12 22:14:21 [INFO]\t[TRAIN] epoch=1, iter=1590/10000, loss=0.8249, lr=0.008558, batch_cost=1.1844, reader_cost=0.00012, ips=13.5093 samples/sec | ETA 02:46:00\n",
      "2021-04-12 22:14:33 [INFO]\t[TRAIN] epoch=1, iter=1600/10000, loss=0.9491, lr=0.008549, batch_cost=1.1840, reader_cost=0.00012, ips=13.5138 samples/sec | ETA 02:45:45\n",
      "2021-04-12 22:14:44 [INFO]\t[TRAIN] epoch=1, iter=1610/10000, loss=0.9182, lr=0.008539, batch_cost=1.1850, reader_cost=0.00012, ips=13.5017 samples/sec | ETA 02:45:42\n",
      "2021-04-12 22:14:56 [INFO]\t[TRAIN] epoch=1, iter=1620/10000, loss=0.8811, lr=0.008530, batch_cost=1.1848, reader_cost=0.00011, ips=13.5040 samples/sec | ETA 02:45:28\n",
      "2021-04-12 22:15:08 [INFO]\t[TRAIN] epoch=1, iter=1630/10000, loss=0.8188, lr=0.008521, batch_cost=1.1847, reader_cost=0.00012, ips=13.5052 samples/sec | ETA 02:45:16\n",
      "2021-04-12 22:15:20 [INFO]\t[TRAIN] epoch=1, iter=1640/10000, loss=0.9457, lr=0.008512, batch_cost=1.1854, reader_cost=0.00012, ips=13.4977 samples/sec | ETA 02:45:09\n",
      "2021-04-12 22:15:32 [INFO]\t[TRAIN] epoch=1, iter=1650/10000, loss=0.9847, lr=0.008503, batch_cost=1.1860, reader_cost=0.00012, ips=13.4908 samples/sec | ETA 02:45:03\n",
      "2021-04-12 22:15:44 [INFO]\t[TRAIN] epoch=1, iter=1660/10000, loss=0.8969, lr=0.008494, batch_cost=1.1857, reader_cost=0.00012, ips=13.4941 samples/sec | ETA 02:44:48\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 154, in <module>\n",
      "    main(args)\n",
      "  File \"train.py\", line 149, in main\n",
      "    keep_checkpoint_max=args.keep_checkpoint_max)\n",
      "  File \"/home/aistudio/PaddleSeg/paddleseg/core/train.py\", line 155, in train\n",
      "    optimizer.step()\n",
      "  File \"</opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/decorator.py:decorator-gen-195>\", line 2, in step\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/wrapped_decorator.py\", line 25, in __impl__\n",
      "    return wrapped_func(*args, **kwargs)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 225, in __impl__\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/optimizer/optimizer.py\", line 923, in step\n",
      "    loss=None, startup_program=None, params_grads=params_grads)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/optimizer/optimizer.py\", line 775, in _apply_optimize\n",
      "    optimize_ops = self._create_optimization_pass(params_grads)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/optimizer/optimizer.py\", line 605, in _create_optimization_pass\n",
      "    self._append_optimize_op(target_block, param_and_grad)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/optimizer/momentum.py\", line 212, in _append_optimize_op\n",
      "    self._regularization_coeff)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "#训练——注意：evaluate会在每次保存save_interval的时候进行一次！\r\n",
    "!python train.py \\\r\n",
    "       --config configs/deeplabv3/My_deep.yml \\\r\n",
    "       --do_eval \\\r\n",
    "       --use_vdl \\\r\n",
    "       --save_interval 250 \\\r\n",
    "       --save_dir output_deeplabv3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.2 从第28500次迭代处进行第二次训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Flops: 40674004992     Total Params: 39120996\r"
     ]
    }
   ],
   "source": [
    "# 也可以在项目提供的7500轮训练结果上继续训练\r\n",
    "!python train.py \\\r\n",
    "       --config configs/deeplabv3/My_deep.yml \\\r\n",
    "       --resume_model output_deeplabv3/iter_28500 \\\r\n",
    "       --do_eval \\\r\n",
    "       --use_vdl \\\r\n",
    "       --save_interval 750 \\\r\n",
    "       --save_dir output_deeplabv3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3. 进行预测\n",
    "将最佳结果的模型参数`output_deeplabv3/best_model/`文件夹拷贝到个人目录`~`\n",
    "\n",
    "PS(postscript，补充一下)：PaddleSeg比较贴心，默认训练的时候会保存最佳的结果，希望以后官方的其他库也能实现这个功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:26: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  def convert_to_list(value, n, name, dtype=np.int):\n",
      "2021-05-10 07:31:59 [INFO]\t\n",
      "---------------Config Information---------------\n",
      "batch_size: 16\n",
      "iters: 50000\n",
      "learning_rate:\n",
      "  decay:\n",
      "    end_lr: 0\n",
      "    power: 0.9\n",
      "    type: poly\n",
      "  value: 0.001\n",
      "loss:\n",
      "  coef:\n",
      "  - 1\n",
      "  types:\n",
      "  - type: CrossEntropyLoss\n",
      "model:\n",
      "  align_corners: false\n",
      "  aspp_out_channels: 256\n",
      "  aspp_ratios:\n",
      "  - 1\n",
      "  - 12\n",
      "  - 24\n",
      "  - 36\n",
      "  backbone:\n",
      "    multi_grid:\n",
      "    - 1\n",
      "    - 2\n",
      "    - 4\n",
      "    output_stride: 8\n",
      "    pretrained: https://bj.bcebos.com/paddleseg/dygraph/resnet50_vd_ssld_v2.tar.gz\n",
      "    type: ResNet50_vd\n",
      "  backbone_indices:\n",
      "  - 3\n",
      "  pretrained: null\n",
      "  type: DeepLabV3\n",
      "optimizer:\n",
      "  momentum: 0.9\n",
      "  type: sgd\n",
      "  weight_decay: 4.0e-05\n",
      "train_dataset:\n",
      "  dataset_root: /home/aistudio/\n",
      "  mode: train\n",
      "  num_classes: 4\n",
      "  train_path: /home/aistudio/train_list.txt\n",
      "  transforms:\n",
      "  - target_size:\n",
      "    - 256\n",
      "    - 256\n",
      "    type: Resize\n",
      "  - type: RandomHorizontalFlip\n",
      "  - type: Normalize\n",
      "  type: Dataset\n",
      "val_dataset:\n",
      "  dataset_root: /home/aistudio/\n",
      "  mode: val\n",
      "  num_classes: 4\n",
      "  transforms:\n",
      "  - target_size:\n",
      "    - 256\n",
      "    - 256\n",
      "    type: Resize\n",
      "  - type: Normalize\n",
      "  type: Dataset\n",
      "  val_path: /home/aistudio/val_list.txt\n",
      "------------------------------------------------\n",
      "W0510 07:32:00.239444   504 device_context.cc:362] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.0, Runtime API Version: 10.1\n",
      "W0510 07:32:00.239503   504 device_context.cc:372] device: 0, cuDNN Version: 7.6.\n",
      "2021-05-10 07:32:03 [INFO]\tLoading pretrained model from https://bj.bcebos.com/paddleseg/dygraph/resnet50_vd_ssld_v2.tar.gz\n",
      "2021-05-10 07:32:03,612 - INFO - Lock 140672240753616 acquired on /home/aistudio/.paddleseg/tmp/resnet50_vd_ssld_v2\n",
      "Connecting to https://bj.bcebos.com/paddleseg/dygraph/resnet50_vd_ssld_v2.tar.gz\n",
      "Downloading resnet50_vd_ssld_v2.tar.gz\n",
      "[==================================================] 100.00%\n",
      "Uncompress resnet50_vd_ssld_v2.tar.gz\n",
      "[==================================================] 100.00%\n",
      "2021-05-10 07:32:07,871 - INFO - Lock 140672240753616 released on /home/aistudio/.paddleseg/tmp/resnet50_vd_ssld_v2\n",
      "2021-05-10 07:32:08 [INFO]\tThere are 275/275 variables loaded into ResNet_vd.\n",
      "2021-05-10 07:32:08 [INFO]\tNumber of predict images = 4608\n",
      "2021-05-10 07:32:08 [INFO]\tLoading pretrained model from /home/aistudio/best_model/model.pdparams\n",
      "2021-05-10 07:32:10 [INFO]\tThere are 312/312 variables loaded into DeepLabV3.\n",
      "2021-05-10 07:32:10 [INFO]\tStart to predict...\n",
      "4608/4608 [==============================] - 162s 35ms/ste\n"
     ]
    }
   ],
   "source": [
    "!python predict.py \\\r\n",
    "       --config configs/deeplabv3/My_deep.yml \\\r\n",
    "       --model_path ~/best_model/model.pdparams \\\r\n",
    "       --image_path ../img_testA/ \\\r\n",
    "       --save_dir ../submit/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<font size=\"4pt\">最后将`~/submit/`下面的`pseudo_color_prediction`文件夹重命名为`resutl`，该文件夹就是最终的结果文件夹，里面是分割后的预测图片</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.0.0b0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
